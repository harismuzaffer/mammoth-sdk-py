"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .objectjobschema import ObjectJobSchema, ObjectJobSchemaTypedDict
import io
from mammoth_analytics.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from mammoth_analytics.utils import (
    FieldMetadata,
    MultipartFormMetadata,
    PathParamMetadata,
    QueryParamMetadata,
    RequestMetadata,
)
import pydantic
from pydantic import model_serializer
from typing import Any, IO, List, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class CreateFileDatasetFileTypedDict(TypedDict):
    file_name: str
    content: Union[bytes, IO[bytes], io.BufferedReader]
    content_type: NotRequired[str]


class CreateFileDatasetFile(BaseModel):
    file_name: Annotated[
        str, pydantic.Field(alias="fileName"), FieldMetadata(multipart=True)
    ]

    content: Annotated[
        Union[bytes, IO[bytes], io.BufferedReader],
        pydantic.Field(alias=""),
        FieldMetadata(multipart=MultipartFormMetadata(content=True)),
    ]

    content_type: Annotated[
        Optional[str],
        pydantic.Field(alias="Content-Type"),
        FieldMetadata(multipart=True),
    ] = None


class CreateFileDatasetRequestBodyTypedDict(TypedDict):
    files: NotRequired[List[CreateFileDatasetFileTypedDict]]


class CreateFileDatasetRequestBody(BaseModel):
    files: Annotated[
        Optional[List[CreateFileDatasetFile]],
        FieldMetadata(multipart=MultipartFormMetadata(file=True)),
    ] = None


class CreateFileDatasetRequestTypedDict(TypedDict):
    request_body: CreateFileDatasetRequestBodyTypedDict
    workspace_id: int
    r"""Workspace refers to a collection of projects. Workspace ID is unique identifier for workspace."""
    project_id: int
    r"""Project ID of the workspace"""
    folder_resource_id: NotRequired[Nullable[str]]
    r"""Resource ID of the folder where the dataset is to be created"""
    append_to_ds_id: NotRequired[Nullable[int]]
    r"""Dataset ID to which the file is being appended"""
    override_target_schema: NotRequired[Nullable[bool]]
    r"""When appending to an existing dataset and this flag is set, the schema of the target dataset will be overridden by schema of the incoming data"""


class CreateFileDatasetRequest(BaseModel):
    request_body: Annotated[
        CreateFileDatasetRequestBody,
        FieldMetadata(request=RequestMetadata(media_type="multipart/form-data")),
    ]

    workspace_id: Annotated[
        int, FieldMetadata(path=PathParamMetadata(style="simple", explode=False))
    ] = 2
    r"""Workspace refers to a collection of projects. Workspace ID is unique identifier for workspace."""

    project_id: Annotated[
        int, FieldMetadata(path=PathParamMetadata(style="simple", explode=False))
    ] = 1
    r"""Project ID of the workspace"""

    folder_resource_id: Annotated[
        OptionalNullable[str],
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = UNSET
    r"""Resource ID of the folder where the dataset is to be created"""

    append_to_ds_id: Annotated[
        OptionalNullable[int],
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = UNSET
    r"""Dataset ID to which the file is being appended"""

    override_target_schema: Annotated[
        OptionalNullable[bool],
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = UNSET
    r"""When appending to an existing dataset and this flag is set, the schema of the target dataset will be overridden by schema of the incoming data"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "folder_resource_id",
            "append_to_ds_id",
            "override_target_schema",
        ]
        nullable_fields = [
            "folder_resource_id",
            "append_to_ds_id",
            "override_target_schema",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


CreateFileDatasetResponseBodyTypedDict = TypeAliasType(
    "CreateFileDatasetResponseBodyTypedDict",
    Union[ObjectJobSchemaTypedDict, List[ObjectJobSchemaTypedDict]],
)
r"""Upload file to create a dataset"""


CreateFileDatasetResponseBody = TypeAliasType(
    "CreateFileDatasetResponseBody", Union[ObjectJobSchema, List[ObjectJobSchema]]
)
r"""Upload file to create a dataset"""


CreateFileDatasetResponseTypedDict = TypeAliasType(
    "CreateFileDatasetResponseTypedDict",
    Union[Any, CreateFileDatasetResponseBodyTypedDict],
)


CreateFileDatasetResponse = TypeAliasType(
    "CreateFileDatasetResponse", Union[Any, CreateFileDatasetResponseBody]
)
