"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from .basesdk import BaseSDK
from mammoth_analytics import errors, models, utils
from mammoth_analytics._hooks import HookContext
from mammoth_analytics.types import OptionalNullable, UNSET
from mammoth_analytics.utils import get_security_from_env
from mammoth_analytics.utils.unmarshal_json_response import unmarshal_json_response
from typing import Any, List, Mapping, Optional, Union


class DataviewPipeline(BaseSDK):
    def get(
        self,
        *,
        workspace_id: int = 2,
        project_id: int = 1,
        dataset_id: int,
        dataview_id: int = 4,
        fields: Optional[str] = "__standard",
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.PipelineInfo:
        r"""Get dataview pipeline information


        This endpoint fetches useful information of a dataview pipeline including some stats. This endpoint, representing a singular resource doesn't allow any filters.


        :param workspace_id: Workspace refers to a collection of projects. Workspace ID is unique identifier for workspace.
        :param project_id: Project ID of the workspace
        :param dataset_id: Id of the dataset
        :param dataview_id: Dataview ID of the dataset
        :param fields: Fields to be returned in a comma-separated format. Check full mode for all fields.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.GetPipelineRequest(
            workspace_id=workspace_id,
            project_id=project_id,
            dataset_id=dataset_id,
            dataview_id=dataview_id,
            fields=fields,
        )

        req = self._build_request(
            method="GET",
            path="/workspaces/{workspace_id}/projects/{project_id}/datasets/{dataset_id}/dataviews/{dataview_id}/pipeline",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=False,
            request_has_path_params=True,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="GetPipeline",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "404", "4XX", "5XX"],
            retry_config=retry_config,
        )

        response_data: Any = None
        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(models.PipelineInfo, http_res)
        if utils.match_response(http_res, "400", "application/json"):
            response_data = unmarshal_json_response(
                errors.GetPipelineBadRequestUnion, http_res
            )
            raise errors.GetPipelineBadRequest(response_data, http_res)
        if utils.match_response(http_res, "404", "application/json"):
            response_data = unmarshal_json_response(
                errors.GetPipelineNotFoundErrorData, http_res
            )
            raise errors.GetPipelineNotFoundError(response_data, http_res)
        if utils.match_response(http_res, ["401", "4XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise errors.MammothAnalyticsDefaultError(
                "API error occurred", http_res, http_res_text
            )
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise errors.MammothAnalyticsDefaultError(
                "API error occurred", http_res, http_res_text
            )

        raise errors.MammothAnalyticsDefaultError(
            "Unexpected response received", http_res
        )

    async def get_async(
        self,
        *,
        workspace_id: int = 2,
        project_id: int = 1,
        dataset_id: int,
        dataview_id: int = 4,
        fields: Optional[str] = "__standard",
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.PipelineInfo:
        r"""Get dataview pipeline information


        This endpoint fetches useful information of a dataview pipeline including some stats. This endpoint, representing a singular resource doesn't allow any filters.


        :param workspace_id: Workspace refers to a collection of projects. Workspace ID is unique identifier for workspace.
        :param project_id: Project ID of the workspace
        :param dataset_id: Id of the dataset
        :param dataview_id: Dataview ID of the dataset
        :param fields: Fields to be returned in a comma-separated format. Check full mode for all fields.
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.GetPipelineRequest(
            workspace_id=workspace_id,
            project_id=project_id,
            dataset_id=dataset_id,
            dataview_id=dataview_id,
            fields=fields,
        )

        req = self._build_request_async(
            method="GET",
            path="/workspaces/{workspace_id}/projects/{project_id}/datasets/{dataset_id}/dataviews/{dataview_id}/pipeline",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=False,
            request_has_path_params=True,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="GetPipeline",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "404", "4XX", "5XX"],
            retry_config=retry_config,
        )

        response_data: Any = None
        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(models.PipelineInfo, http_res)
        if utils.match_response(http_res, "400", "application/json"):
            response_data = unmarshal_json_response(
                errors.GetPipelineBadRequestUnion, http_res
            )
            raise errors.GetPipelineBadRequest(response_data, http_res)
        if utils.match_response(http_res, "404", "application/json"):
            response_data = unmarshal_json_response(
                errors.GetPipelineNotFoundErrorData, http_res
            )
            raise errors.GetPipelineNotFoundError(response_data, http_res)
        if utils.match_response(http_res, ["401", "4XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise errors.MammothAnalyticsDefaultError(
                "API error occurred", http_res, http_res_text
            )
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise errors.MammothAnalyticsDefaultError(
                "API error occurred", http_res, http_res_text
            )

        raise errors.MammothAnalyticsDefaultError(
            "Unexpected response received", http_res
        )

    def edit(
        self,
        *,
        workspace_id: int = 2,
        project_id: int = 1,
        dataset_id: int,
        dataview_id: int = 4,
        patches: Union[List[models.PipelinePatch], List[models.PipelinePatchTypedDict]],
        skip_validation: Optional[bool] = False,
        force_run: Optional[bool] = False,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.EditPipelineResponse:
        r"""Edit and perform bulk operations on a dataview pipeline


        This endpoint allows
        - Editing a pipeline. Supported operations are
        - Reorder
        - Reset
        - Run
        - Discard-changes
        - Set auto-run
        - Bulk operations on(items of) the pipeline
        - suspend
        - restore
        - discard


        :param workspace_id: Workspace refers to a collection of projects. Workspace ID is unique identifier for workspace.
        :param project_id: Project ID of the workspace
        :param dataset_id: Id of the dataset
        :param dataview_id: Dataview ID of the dataset
        :param patches:
        :param skip_validation:
        :param force_run:
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.EditPipelineRequest(
            workspace_id=workspace_id,
            project_id=project_id,
            dataset_id=dataset_id,
            dataview_id=dataview_id,
            skip_validation=skip_validation,
            force_run=force_run,
            pipeline_patches=models.PipelinePatches(
                patches=utils.get_pydantic_model(patches, List[models.PipelinePatch]),
            ),
        )

        req = self._build_request(
            method="PATCH",
            path="/workspaces/{workspace_id}/projects/{project_id}/datasets/{dataset_id}/dataviews/{dataview_id}/pipeline",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=True,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request.pipeline_patches, False, False, "json", models.PipelinePatches
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = self.do_request(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="EditPipeline",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "404", "4XX", "5XX"],
            retry_config=retry_config,
        )

        response_data: Any = None
        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(models.EditPipelineResponseBody, http_res)
        if utils.match_response(http_res, "202", "application/json"):
            return unmarshal_json_response(models.JobResponse, http_res)
        if utils.match_response(http_res, "400", "application/json"):
            response_data = unmarshal_json_response(
                errors.EditPipelineBadRequestUnion, http_res
            )
            raise errors.EditPipelineBadRequest(response_data, http_res)
        if utils.match_response(http_res, "404", "application/json"):
            response_data = unmarshal_json_response(
                errors.EditPipelineNotFoundErrorData, http_res
            )
            raise errors.EditPipelineNotFoundError(response_data, http_res)
        if utils.match_response(http_res, ["401", "4XX"], "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise errors.MammothAnalyticsDefaultError(
                "API error occurred", http_res, http_res_text
            )
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = utils.stream_to_text(http_res)
            raise errors.MammothAnalyticsDefaultError(
                "API error occurred", http_res, http_res_text
            )

        raise errors.MammothAnalyticsDefaultError(
            "Unexpected response received", http_res
        )

    async def edit_async(
        self,
        *,
        workspace_id: int = 2,
        project_id: int = 1,
        dataset_id: int,
        dataview_id: int = 4,
        patches: Union[List[models.PipelinePatch], List[models.PipelinePatchTypedDict]],
        skip_validation: Optional[bool] = False,
        force_run: Optional[bool] = False,
        retries: OptionalNullable[utils.RetryConfig] = UNSET,
        server_url: Optional[str] = None,
        timeout_ms: Optional[int] = None,
        http_headers: Optional[Mapping[str, str]] = None,
    ) -> models.EditPipelineResponse:
        r"""Edit and perform bulk operations on a dataview pipeline


        This endpoint allows
        - Editing a pipeline. Supported operations are
        - Reorder
        - Reset
        - Run
        - Discard-changes
        - Set auto-run
        - Bulk operations on(items of) the pipeline
        - suspend
        - restore
        - discard


        :param workspace_id: Workspace refers to a collection of projects. Workspace ID is unique identifier for workspace.
        :param project_id: Project ID of the workspace
        :param dataset_id: Id of the dataset
        :param dataview_id: Dataview ID of the dataset
        :param patches:
        :param skip_validation:
        :param force_run:
        :param retries: Override the default retry configuration for this method
        :param server_url: Override the default server URL for this method
        :param timeout_ms: Override the default request timeout configuration for this method in milliseconds
        :param http_headers: Additional headers to set or replace on requests.
        """
        base_url = None
        url_variables = None
        if timeout_ms is None:
            timeout_ms = self.sdk_configuration.timeout_ms

        if server_url is not None:
            base_url = server_url
        else:
            base_url = self._get_url(base_url, url_variables)

        request = models.EditPipelineRequest(
            workspace_id=workspace_id,
            project_id=project_id,
            dataset_id=dataset_id,
            dataview_id=dataview_id,
            skip_validation=skip_validation,
            force_run=force_run,
            pipeline_patches=models.PipelinePatches(
                patches=utils.get_pydantic_model(patches, List[models.PipelinePatch]),
            ),
        )

        req = self._build_request_async(
            method="PATCH",
            path="/workspaces/{workspace_id}/projects/{project_id}/datasets/{dataset_id}/dataviews/{dataview_id}/pipeline",
            base_url=base_url,
            url_variables=url_variables,
            request=request,
            request_body_required=True,
            request_has_path_params=True,
            request_has_query_params=True,
            user_agent_header="user-agent",
            accept_header_value="application/json",
            http_headers=http_headers,
            security=self.sdk_configuration.security,
            get_serialized_body=lambda: utils.serialize_request_body(
                request.pipeline_patches, False, False, "json", models.PipelinePatches
            ),
            timeout_ms=timeout_ms,
        )

        if retries == UNSET:
            if self.sdk_configuration.retry_config is not UNSET:
                retries = self.sdk_configuration.retry_config

        retry_config = None
        if isinstance(retries, utils.RetryConfig):
            retry_config = (retries, ["429", "500", "502", "503", "504"])

        http_res = await self.do_request_async(
            hook_ctx=HookContext(
                config=self.sdk_configuration,
                base_url=base_url or "",
                operation_id="EditPipeline",
                oauth2_scopes=[],
                security_source=get_security_from_env(
                    self.sdk_configuration.security, models.Security
                ),
            ),
            request=req,
            error_status_codes=["400", "401", "404", "4XX", "5XX"],
            retry_config=retry_config,
        )

        response_data: Any = None
        if utils.match_response(http_res, "200", "application/json"):
            return unmarshal_json_response(models.EditPipelineResponseBody, http_res)
        if utils.match_response(http_res, "202", "application/json"):
            return unmarshal_json_response(models.JobResponse, http_res)
        if utils.match_response(http_res, "400", "application/json"):
            response_data = unmarshal_json_response(
                errors.EditPipelineBadRequestUnion, http_res
            )
            raise errors.EditPipelineBadRequest(response_data, http_res)
        if utils.match_response(http_res, "404", "application/json"):
            response_data = unmarshal_json_response(
                errors.EditPipelineNotFoundErrorData, http_res
            )
            raise errors.EditPipelineNotFoundError(response_data, http_res)
        if utils.match_response(http_res, ["401", "4XX"], "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise errors.MammothAnalyticsDefaultError(
                "API error occurred", http_res, http_res_text
            )
        if utils.match_response(http_res, "5XX", "*"):
            http_res_text = await utils.stream_to_text_async(http_res)
            raise errors.MammothAnalyticsDefaultError(
                "API error occurred", http_res, http_res_text
            )

        raise errors.MammothAnalyticsDefaultError(
            "Unexpected response received", http_res
        )
